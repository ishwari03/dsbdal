{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Downloading and Importing Libraries**"
      ],
      "metadata": {
        "id": "lR_zFMXAut4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2dUweo1oJE_",
        "outputId": "ff130ca2-1db1-44f8-cbf7-91c206b25d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re"
      ],
      "metadata": {
        "id": "SVIyT8--oMzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaiIYgDeoVgo",
        "outputId": "a1239fcf-ce2d-424b-d2ab-d23527fda48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating the doc for Text Analysis**"
      ],
      "metadata": {
        "id": "mieHDQ2xoz5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text= \"Hello everyone! I am Disha Gore. I am in TY pursuing Bachelors Degree in Computer Science at MES Wadia College Of Engineering. I have good knowledge about C, C++, Java, Jython, HTML, CSS, JS, Bootstrap and Databases. In my free time, I like listening t music as it makes me feel relaxed.\""
      ],
      "metadata": {
        "id": "18qErTEzpE11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SENTENCE TOKENIZATION\n",
        "from nltk.tokenize import sent_tokenize\n",
        "var1 = sent_tokenize(text)\n",
        "print(var1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXjeC8ydqnue",
        "outputId": "e15d709e-ae6f-461c-a7b8-e264a1b5a77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello everyone!', 'I am Disha Gore.', 'I am in TY pursuing Bachelors Degree in Computer Science at MES Wadia College Of Engineering.', 'I have good knowledge about C, C++, Java, Jython, HTML, CSS, JS, Bootstrap and Databases.', 'In my free time, I like listening t music as it makes me feel relaxed.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WORD TOKENIZATION\n",
        "from nltk.tokenize import word_tokenize\n",
        "var2 = word_tokenize(text)\n",
        "print(var2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3xgfVEmq4qQ",
        "outputId": "5c860652-aa37-4ef8-dc1c-6d116a518c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'everyone', '!', 'I', 'am', 'Disha', 'Gore', '.', 'I', 'am', 'in', 'TY', 'pursuing', 'Bachelors', 'Degree', 'in', 'Computer', 'Science', 'at', 'MES', 'Wadia', 'College', 'Of', 'Engineering', '.', 'I', 'have', 'good', 'knowledge', 'about', 'C', ',', 'C++', ',', 'Java', ',', 'Jython', ',', 'HTML', ',', 'CSS', ',', 'JS', ',', 'Bootstrap', 'and', 'Databases', '.', 'In', 'my', 'free', 'time', ',', 'I', 'like', 'listening', 't', 'music', 'as', 'it', 'makes', 'me', 'feel', 'relaxed', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Removing Punctuation and Stop words**"
      ],
      "metadata": {
        "id": "GmBT7IztrU5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "var3 = set(stopwords.words('english'))\n",
        "print(var3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjT5zHeArS4u",
        "outputId": "6bf862b4-b7c0-4862-bfdc-84a88e599daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'each', 'they', 'when', 'him', 'all', 'does', 'more', 'needn', \"wasn't\", 'over', 'where', \"haven't\", 'them', 've', 'the', 'both', 'll', 'from', 'her', 'again', 'other', \"didn't\", 'won', 'had', 'to', 'there', \"isn't\", 'are', 'while', \"you've\", 'she', 'this', 'ours', 'few', \"needn't\", \"shan't\", 'did', 't', 'been', 'yourselves', 'be', 'being', 'me', 'their', 'a', 'before', 'until', \"should've\", 'nor', 'against', 'what', 'between', 'most', 'about', \"wouldn't\", 'with', 'he', 'o', 'out', 'we', 're', \"doesn't\", 'yours', 'mustn', 'at', 'shan', 'ma', 'so', 'into', 'have', 'his', 'having', 'is', 'hers', 'any', 'here', 'no', \"that'll\", 'too', 'has', 'once', 'haven', 'of', 'my', 'you', 'some', 'as', \"she's\", 'whom', 'through', 'hasn', 'aren', 'on', \"you're\", 'weren', 'was', 'd', 'themselves', 'itself', 'but', 'its', \"you'd\", \"couldn't\", 'doing', 's', \"hadn't\", 'theirs', 'further', 'than', 'hadn', \"mightn't\", 'didn', 'yourself', 'that', \"mustn't\", 'those', 'own', 'will', 'by', 'same', \"don't\", 'in', 'should', 'our', 'i', 'couldn', 'very', 'ourselves', 'which', 'for', \"it's\", 'herself', \"weren't\", 'wasn', 'wouldn', 'do', \"hasn't\", 'such', 'am', 'after', 'not', 'then', 'under', 'why', 'above', 'don', 'y', \"aren't\", 'only', 'below', \"shouldn't\", 'if', 'who', 'can', 'now', 'myself', 'isn', 'm', 'because', 'an', 'off', 'himself', 'how', \"you'll\", 'and', 'during', 'up', 'down', 'these', 'doesn', 'mightn', 'or', 'your', 'it', 'shouldn', 'were', 'just', \"won't\", 'ain'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = re.sub('[^a-zA-Z]',' ',text)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4hiTncor6Lv",
        "outputId": "fde3cb6e-3893-46c9-e2db-93fa288e7e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello everyone  I am Disha Gore  I am in TY pursuing Bachelors Degree in Computer Science at MES Wadia College Of Engineering  I have good knowledge about C  C    Java  Jython  HTML  CSS  JS  Bootstrap and Databases  In my free time  I like listening t music as it makes me feel relaxed \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text.lower())\n",
        "filtered_text = []\n",
        "for word in tokens:\n",
        "  if word not in var3:\n",
        "    filtered_text.append(word)\n",
        "print(\"Tokenized Sentence: \", tokens)\n",
        "print(\"Filtered Sentence: \", filtered_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFqDKtNcsKEv",
        "outputId": "240b6bad-7769-437a-ba03-4cbea245a67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Sentence:  ['hello', 'everyone', 'i', 'am', 'disha', 'gore', 'i', 'am', 'in', 'ty', 'pursuing', 'bachelors', 'degree', 'in', 'computer', 'science', 'at', 'mes', 'wadia', 'college', 'of', 'engineering', 'i', 'have', 'good', 'knowledge', 'about', 'c', 'c', 'java', 'jython', 'html', 'css', 'js', 'bootstrap', 'and', 'databases', 'in', 'my', 'free', 'time', 'i', 'like', 'listening', 't', 'music', 'as', 'it', 'makes', 'me', 'feel', 'relaxed']\n",
            "Filtered Sentence:  ['hello', 'everyone', 'disha', 'gore', 'ty', 'pursuing', 'bachelors', 'degree', 'computer', 'science', 'mes', 'wadia', 'college', 'engineering', 'good', 'knowledge', 'c', 'c', 'java', 'jython', 'html', 'css', 'js', 'bootstrap', 'databases', 'free', 'time', 'like', 'listening', 'music', 'makes', 'feel', 'relaxed']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stemmatization**"
      ],
      "metadata": {
        "id": "WsvZ041ps4jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "var = [\"write\", \"writing\", \"wrote\", \"writes\",\"reading\",\"reads\"]\n",
        "ps = PorterStemmer() #brings word to its root form\n",
        "for w in var:\n",
        "  root_word = ps.stem(w)\n",
        "  print(root_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BIvLn_LszW6",
        "outputId": "4084e4bc-bba9-43d3-87e5-da11925492ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write\n",
            "write\n",
            "wrote\n",
            "write\n",
            "read\n",
            "read\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Lemmatization**"
      ],
      "metadata": {
        "id": "j51lBI0bt3cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "text = \"studies studying cries cry\"\n",
        "tt = nltk.word_tokenize(text)\n",
        "print(text)\n",
        "for w in tt:\n",
        "  print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80UUCS1ytlNj",
        "outputId": "2f874f8b-8e44-429f-abf2-d2d39c44328d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "studies studying cries cry\n",
            "Lemma for studies is study\n",
            "Lemma for studying is studying\n",
            "Lemma for cries is cry\n",
            "Lemma for cry is cry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DNx-cqibujnD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}